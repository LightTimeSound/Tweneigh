{
    "cells": [
     {
         "cell_type": "markdown",
         "source": [
             "### Explanation of Key Concepts\n\nA custom loss function allows you to define your own error metric, tailored to your specific problem. In PyTorch, you can create a custom loss function by extending the `nn.Module` class and implementing the `forward` method. This method takes two arguments: the predicted output and the target output.\n\nIn this tutorial, we will create a custom loss function for a simple regression problem, and we'll use the Boston Housing dataset as our use-case."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "# Importing required libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.datasets import load_boston\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "### Contextualize the Topic\n\nThe Boston Housing dataset is a popular dataset for regression tasks. It contains information about various attributes of houses in Boston, and our goal is to predict the median value of a house given its features. We'll start by loading the dataset, splitting it into training and testing sets, and normalizing the features."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "# Load the Boston Housing dataset\nboston = load_boston()\nX, y = boston.data, boston.target\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Convert the data to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "### Explain Parameters and Settings\n\nIn this tutorial, we will implement a custom loss function called `MeanAbsolutePercentageError` (MAPE), which calculates the mean absolute percentage difference between the predicted and target values. This loss function is helpful when you want to minimize the relative error rather than the absolute error."
         ],
         "metadata": {}
     },
     {
         "cell_type": "markdown",
         "source": [
             "### Custom Loss Function: Mean Absolute Percentage Error\n\nTo implement our custom loss function, we'll extend the `nn.Module` class and override the `forward` method. The `forward` method should compute the loss between the predicted and target values."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "class MeanAbsolutePercentageError(nn.Module):\n    def __init__(self):\n        super(MeanAbsolutePercentageError, self).__init__()\n\n    def forward(self, y_pred, y_true):\n        return torch.mean(torch.abs((y_true - y_pred) / y_true)) * 100"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "### Training Process\n\nNow, let's define a simple neural network for regression, set up the optimizer, and train the model using our custom loss function."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "# Define a simple neural network for regression\nclass RegressionModel(nn.Module):\n    def __init__(self, input_size):\n        super(RegressionModel, self).__init__()\n        self.layer1 = nn.Linear(input_size, 64)\n        self.layer2 = nn.Linear(64, 32)\n        self.output_layer = nn.Linear(32, 1)\n\n def forward(self, x):\n        x = torch.relu(self.layer1(x))\n        x = torch.relu(self.layer2(x))\n        return self.output_layer(x)\n\n# Initialize the model, loss function, and optimizer\nmodel = RegressionModel(input_size=X_train.shape[1])\nloss_function = MeanAbsolutePercentageError()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    y_pred = model(X_train_tensor)\n    loss = loss_function(y_pred.squeeze(), y_train_tensor)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "### Evaluation and Interpretation\n\nAfter training the model, we can evaluate its performance on the test set. We'll compute the Mean Absolute Percentage Error (MAPE) for the test set and interpret the results."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "# Evaluate the model on the test set\nmodel.eval()\nwith torch.no_grad():\n    y_test_pred = model(X_test_tensor)\n    test_loss = loss_function(y_test_pred.squeeze(), y_test_tensor)\n    print(f'Test Loss (MAPE): {test_loss.item():.4f}')"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "### Practical Application\n\nCustom loss functions, such as the one we implemented in this tutorial, can be used to fine-tune a model's performance on specific tasks. By using a loss function that is more relevant to the problem, you increase the likelihood of obtaining better predictions and improving the overall performance of the model."
         ],
         "metadata": {}
     },
     {
         "cell_type": "markdown",
         "source": [
             "### Next Steps\n\nNow that you've learned how to create a custom loss function in PyTorch, you can explore more advanced techniques and loss functions that are better suited to specific problem domains. Additionally, you can experiment with different network architectures, hyperparameters, and optimization algorithms to further improve your model's performance."
         ],
         "metadata": {}
     }
 ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.11.1"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 }
