{
   "cells": [
    {
        "cell_type": "markdown",
        "source": [
            "# Forward Propagation in Neural Networks"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "In this tutorial, we will cover the concept of forward propagation, which is the process of moving through a neural network from input to output, applying the relevant weights and activation functions. We will use PyTorch to create a simple feedforward neural network and demonstrate forward propagation on a sample dataset."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Key Concepts"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Forward propagation is the process by which input data is passed through the layers of a neural network to produce an output. During this process, each neuron in the network receives input from the previous layer, multiplies it with the corresponding weights, applies an activation function, and passes the result as input to neurons in the next layer. The final output is then used to compute the loss, which is minimized during training using backpropagation."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Dataset and Use-Case"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "We will use a simple dataset for this tutorial. Our goal is to predict whether a given number is even or odd. We will create a feedforward neural network with one hidden layer and demonstrate forward propagation using PyTorch."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Import Libraries and Create Dataset"
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "import torch\n",
            "import torch.nn as nn\n",
            "\n",
            "# Create a simple dataset\n",
            "data = torch.tensor([[2, 0], [5, 1], [8, 0], [12, 0], [15, 1], [17, 1]], dtype=torch.float32)\n",
            "X = data[:, 0]\n",
            "y = data[:, 1]\n",
            "\n",
            "print('Dataset:')\n",
            "print(data)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Feedforward Neural Network"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "We will create a simple feedforward neural network with one input layer, one hidden layer, and one output layer. The hidden layer will have two neurons, and we will use the ReLU activation function. The output layer will have a single neuron with a sigmoid activation function to produce a probability value between 0 and 1."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Define the neural network model\n",
            "class SimpleNN(nn.Module):\n",
            "\n",
            "    def __init__(self):\n",
            "        super(SimpleNN, self).__init__()\n",
            "\n",
            "        # Define layers\n",
            "        self.hidden_layer = nn.Linear(1, 2)\n",
            "        self.output_layer = nn.Linear(2, 1)\n",
            "\n",
            "        # Define activation functions\n",
            "        self.relu = nn.ReLU()\n",
            "        self.sigmoid = nn.Sigmoid()\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.hidden_layer(x)\n",
            "        x = self.relu(x)\n",
            "        x = self.output_layer(x)\n",
            "        x = self.sigmoid(x)\n",
            "\n",
            "        return x\n",
            "\n",
            "# Instantiate the model\n",
            "model = SimpleNN()\n",
            "print(model)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Forward Propagation"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Now that we have our neural network model defined, we can perform forward propagation by passing the input data through the model. This will produce an output probability value for each input data point."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Perform forward propagation\n",
            "X_input = X.view(-1, 1)  # Reshape input data\n",
            "\n",
            "# Pass the input data through the model\n",
            "output_probs = model(X_input)\n",
            "\n",
            "print('Output Probabilities:')\n"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Interpretation and Evaluation"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "The output probabilities can be interpreted as the model's prediction of whether a given number is even or odd. We can convert these probabilities to binary predictions by applying a threshold
(e.g., 0.5). Note that the model has not been trained yet, so the predictions are likely to be incorrect at this stage."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Convert probabilities to binary predictions\n",
            "threshold = 0.5\n",
            "predictions = (output_probs > threshold).float()\n",
            "\n",
            "# Compare predictions with true labels\n",
            "print('Predictions:')\n",
            "print(predictions.view(-1))\n",
            "print('True labels:')\n",
            "print(y)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Practical Application"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "In practical applications, forward propagation is an essential step in training and evaluating neural networks. Once the model is trained, you can use forward propagation to make predictions on new data and assess the performance of the model. For example, you could use a similar neural network to classify images, detect anomalies in time-series data, or predict stock prices."
        ],
        "metadata": {}
    }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
