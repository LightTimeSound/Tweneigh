{
   "cells": [
    {
        "cell_type": "markdown",
        "source": [
            "### L1 Loss in PyTorch"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "**Key Concepts**"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "L1 Loss is a type of loss function that calculates the absolute difference between the predicted and target values. It is also known as the Least Absolute Deviations (LAD) or Mean Absolute Error (MAE)."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "**Contextualizing the Topic**"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "In this tutorial, we will create a simple regression problem with synthetic data to demonstrate how to use the L1 Loss function in PyTorch."        
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "**Parameters and Settings**"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "The primary parameter for the L1 Loss function in PyTorch is `reduction`, which can be set to 'none', 'mean', or 'sum'. By default, it is set to 'mean', which calculates the average of the absolute differences. If set to 'sum', it calculates the total absolute difference, and if set to 'none', it returns the individual absolute differences."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "**Training Process**"
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "import torch\nimport torch.nn as nn\n\n# Synthetic data\nx = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\ny_true = torch.tensor([2.0, 4.0, 6.0, 8.0, 10.0])\n\n# Model\nmodel = nn.Linear(1, 1)\n\n# Loss function\nl1_loss = nn.L1Loss()\n\n# Optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Training loop\nfor epoch in range(100):\n    y_pred = model(x.unsqueeze(1))\n    loss = l1_loss(y_pred, y_true.unsqueeze(1))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "**Evaluation and Interpretation**"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "After training the model, we can evaluate the performance by calculating the L1 Loss on new data. Lower values indicate better performance."        
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "x_test = torch.tensor([6.0, 7.0, 8.0, 9.0, 10.0])\ny_test_true = torch.tensor([12.0, 14.0, 16.0, 18.0, 20.0])\n\ny_test_pred = model(x_test.unsqueeze(1))\ntest_loss = l1_loss(y_test_pred, y_test_true.unsqueeze(1))\nprint(f'Test Loss: {test_loss.item()}')"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "**Practical Application**"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "L1 Loss is commonly used in regression tasks, such as predicting house prices or stock prices. It is less sensitive to outliers compared to Mean Squared Error (MSE) Loss, making it suitable for problems with noisy data."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "**Next Steps**"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Now that you have learned about L1 Loss in PyTorch, consider exploring other loss functions, such as Mean Squared Error (MSE) Loss, Cross-Entropy Loss, or Binary Cross-Entropy Loss. Understanding different loss functions will help you choose the most appropriate one for your specific problem."
        ],
        "metadata": {}
    }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
