{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 1. Introduction to PPO",
            "PPO is a popular reinforcement learning algorithm that aims to address the trade-off between exploration and exploitation by using a trust region optimization approach. It is an on-policy algorithm that works by updating the policy in a way that doesn't deviate too much from the previous policy.",
            "We'll now move on to implementing PPO with stable_baselines3 and gym."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
         "### Importing necessary libraries"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
         "import gym\n",
         "from stable_baselines3 import PPO\n",
         "from stable_baselines3.common.vec_env import DummyVecEnv\n",
         "from stable_baselines3.common.evaluation import evaluate_policy"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
          "### Creating and configuring the PPO agent"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
          "ppo_agent = PPO('MlpPolicy', env, verbose=1)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
          "### 4. Training the PPO agent"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
          "ppo_agent.learn(total_timesteps=20000)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
          "### 5. Evaluating the PPO agent"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
          "mean_reward, std_reward = evaluate_policy(ppo_agent, env, n_eval_episodes=10)\n",
          "print(f'Mean reward: {mean_reward} Â± {std_reward}')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
          "### Saving and loading the trained PPO agent"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
          "ppo_agent.save('ppo_cartpole')\n",
          "ppo_agent = PPO.load('ppo_cartpole')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
          "### Testing the trained PPO agent"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
          "obs = env.reset()\n",
          "for _ in range(1000):\n",
          "    action, _ = ppo_agent.predict(obs)\n",
          "    obs, reward, done, info = env.step(action)\n",
          "    env.render()\n",
          "    if done:\n",
          "        obs = env.reset()\n",
          "env.close()"
         ]
      }
   ]
   ,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
