{
    "cells": [
     {
         "cell_type": "markdown",
         "source": [
             "# Introduction to Data Loading and Preprocessing in PyTorch\n",
             "\n",
             "In this tutorial, we will learn how to load and preprocess data using PyTorch. PyTorch is a popular deep learning framework that provides tools for data loading and preprocessing, which help streamline the process of preparing data for training and evaluation. We will cover the following topics:\n",
             "\n",
             "1. Loading a dataset using PyTorch's `Dataset` class\n",
             "2. Transforming data using PyTorch's `Transform` class\n",
             "3. Combining datasets and transformations using `DataLoader`\n",
             "4. Splitting datasets into training and validation sets\n",
             "5. Practical example: Loading and preprocessing the CIFAR-10 dataset"
         ],
         "metadata": {}
     },
     {
         "cell_type": "markdown",
         "source": [
             "# Loading a dataset using PyTorch's `Dataset` class\n",
             "\n",
             "PyTorch provides a `Dataset` class that makes it easy to load and preprocess data. In this section, we will learn how to create a custom dataset by extending the `Dataset` class and implementing the required methods: `__len__()` and `__getitem__()`.\n",
             "\n",
             "First, let's import the necessary libraries."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "import os\n",
             "import torch\n",
             "from torch.utils.data import Dataset\n",
             "from PIL import Image"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "Now, let's create a custom dataset class for loading images and their corresponding labels."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "class CustomImageDataset(Dataset):\n",
             "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
             "        self.img_labels = pd.read_csv(annotations_file)\n",
             "        self.img_dir = img_dir\n",
             "        self.transform = transform\n",
             "        self.target_transform = target_transform\n",
             "\n",
             "    def __len__(self):\n",
             "        return len(self.img_labels)\n",
             "\n",
             "    def __getitem__(self, idx):\n",
             "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
             "        image = Image.open(img_path).convert('RGB')\n",
             "        label = self.img_labels.iloc[idx, 1]\n",
             "        if self.transform:\n",
             "            image = self.transform(image)\n",
             "        if self.target_transform:\n",
             "            label = self.target_transform(label)\n",
             "        return image, label"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "# Transforming data using PyTorch's `Transform` class\n",
             "\n",
             "PyTorch provides a `Transform` class that allows you to apply various transformations to your data, such as resizing, normalization, and data augmentation. In this section, we will learn how to use built-in transforms and create custom transforms.\n",
             "\n",
             "First, let's import the necessary libraries."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "import torchvision.transforms as transforms"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "Now, let's create a transform pipeline that applies various transformations to our images."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "transform = transforms.Compose([\n",
             "    transforms.Resize(256),\n",
             "    transforms.CenterCrop(224),\n",
             "    transforms.ToTensor(),\n",
             "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
             "])"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "To create a custom transform, you need to define a class with a `__call__()` method. Here's an example of a custom transform that converts images to grayscale."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "class ToGrayscale:\n",
             "    def __call__(self, image):\n",
             "        return image.convert('L')"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "# Combining datasets and transformations using `DataLoader`\n",
             "\n",
             "PyTorch provides a `DataLoader` class that makes it easy to load and preprocess data in parallel using multiple worker processes. In this section, we will learn how to create a `DataLoader` instance for our custom dataset and apply the transform pipeline we created earlier.\n",
             "\n",
             "First, let's import the necessary libraries."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "from torch.utils.data import DataLoader"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "Now, let's create a `DataLoader` instance for our custom dataset."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "annotations_file = 'path/to/annotations.csv'\n",
             "img_dir = 'path/to/images'\n",
             "dataset = CustomImageDataset(annotations_file, img_dir, transform=transform)\n",
             "data_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "# Splitting datasets into training and validation sets\n",
             "\n",
             "In order to evaluate the performance of our model, we need to split our dataset into training and validation sets. In this section, we will learn how to use PyTorch's `random_split()` function to split our dataset.\n",
             "\n",
             "First, let's import the necessary libraries."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "from torch.utils.data import random_split"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "Now, let's split our dataset into training and validation sets."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "train_size = int(0.8 * len(dataset))\n",
             "val_size = len(dataset) - train_size\n",
             "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "# Practical example: Loading and preprocessing the CIFAR-10 dataset\n",
             "\n",
             "In this section, we will demonstrate how to load and preprocess the CIFAR-10 dataset using the concepts we have learned so far. The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.\n",
             "\n",
             "First, let's import the necessary libraries."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "import torchvision.datasets as datasets"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "Now, let's load the CIFAR-10 dataset and apply the transform pipeline we created earlier."
         ],
         "metadata": {}
     },
     {
         "cell_type": "code",
         "source": [
             "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
             "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
             "\n",
             "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=4)\n",
             "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=4)"
         ],
         "metadata": {},
         "outputs": [],
         "execution_count": null
     },
     {
         "cell_type": "markdown",
         "source": [
             "# Next Steps\n",
             "\n",
             "You have learned how to create custom datasets, apply built-in and custom transforms, use DataLoader for efficient data loading, and split datasets into training and validation sets.\n",
             "\n",
             "To further enhance your skills and knowledge, consider exploring the following topics:\n",
             "\n",
             "1. Building and training deep learning models in PyTorch\n",
             "2. Hyperparameter tuning and model selection\n",
             "3. Advanced data augmentation techniques\n",
             "4. Working with other popular datasets, such as ImageNet or COCO\n",
             "\n",
             "Keep practicing and experimenting with different datasets and preprocessing techniques to become proficient in using PyTorch for deep learning applications. Good luck!"
         ],
         "metadata": {}
     }
 ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3 (ipykernel)",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.11.1"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 }
