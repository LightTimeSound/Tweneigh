{
   "cells": [
    {
        "cell_type": "markdown",
        "source": [
            "# Neural Networks: Understanding the Basic Structure"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Key Concepts of Neural Networks"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "A neural network is a computational model inspired by the human brain. It consists of interconnected nodes called neurons, organized into layers. A typical neural network has three main types of layers:\n\n1. Input layer: Represents the input features of the dataset.\n2. Hidden layer(s): Perform transformations on the input data to extract useful information.\n3. Output layer: Provides the final prediction or classification based on the input and hidden layers."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Context: MNIST Handwritten Digit Classification"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "In this tutorial, we will use PyTorch to create a simple neural network for classifying handwritten digits from the MNIST dataset. The dataset consists of 70,000 grayscale images of size 28x28
pixels, each representing a digit from 0 to 9."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Import necessary libraries\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "\n",
            "# Set random seed for reproducibility\n",
            "torch.manual_seed(42)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Designing a Neural Network for Digit Classification"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "We will create a simple feedforward neural network with one hidden layer. The input layer will have 784 neurons (28x28 pixels), the hidden layer will have 128 neurons, and the output layer will have 10 neurons, representing the digits 0-9. We'll use the ReLU activation function for the hidden layer and softmax for the output layer."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Define the neural network class\n",
            "class DigitClassifier(nn.Module):\n",
            "    def __init__(self):\n",
            "        super(DigitClassifier, self).__init__()\n",
            "        self.fc1 = nn.Linear(28 * 28, 128)\n",
            "        self.fc2 = nn.Linear(128, 10)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = torch.flatten(x, start_dim=1)\n",
            "        x = self.fc1(x)\n",
            "        x = torch.relu(x)\n",
            "        x = self.fc2(x)\n",
            "        output = torch.softmax(x, dim=1)\n",
            "        return output\n",
            "\n",
            "# Create an instance of the neural network\n",
            "model = DigitClassifier()\n",
            "\n",
            "# Print the neural network structure\n",
            "print(model)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Training the Neural Network"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "To train the neural network, we need to define a loss function and an optimizer. We'll use cross-entropy loss for this classification problem and the stochastic gradient descent (SGD) optimizer. Additionally, we'll set up the MNIST dataset and create data loaders for training and testing."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "from torch.utils.data import DataLoader\n",
            "from torchvision import datasets, transforms\n",
            "\n",
            "# Set up the MNIST dataset and data loaders\n",
            "transform = transforms.Compose([transforms.ToTensor()])\n",
            "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
            "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
            "\n",
            "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
            "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
            "\n",
            "# Define the loss function and optimizer\n",
            "loss_fn = nn.CrossEntropyLoss()\n",
            "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "Now we can train the neural network for several epochs. For each epoch, we will iterate through the training data in mini-batches and update the model weights using backpropagation."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "def train(model, data_loader, loss_fn, optimizer, device):\n",
            "    model.train()\n",
            "    for batch_idx, (data, target) in enumerate(data_loader):\n",
            "        data, target = data.to(device), target.to(device)\n",
            "        optimizer.zero_grad()\n",
            "        output = model(data)\n",
            "        loss = loss_fn(output, target)\n",
            "        loss.backward()\n",
            "        optimizer.step()\n",
            "\n",
            "# Train the model for 10 epochs\n",
            "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
            "model.to(device)\n",
            "\n",
            "for epoch in range(1, 11):\n",
            "    train(model, train_loader, loss_fn, optimizer, device)\n",
            "    print(f'Epoch {epoch} completed.')"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Saving and Loading the Trained Model"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "After training the neural network, we can save the model weights to a file and load them later for reuse or fine-tuning."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Save the trained model\n",
            "torch.save(model.state_dict(), 'digit_classifier.pth')\n",
            "\n",
            "# Load the saved model\n",
            "loaded_model = DigitClassifier()\n",
            "loaded_model.load_state_dict(torch.load('digit_classifier.pth'))\n",
            "loaded_model.eval()"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Evaluating the Model and Interpreting Results"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "We will now evaluate the model on the test set and calculate its accuracy. We'll also visualize some predictions to get a better understanding of the model's performance."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "def test(model, data_loader, device):\n",
            "    model.eval()\n",
            "    correct = 0\n",
            "\n",
            "    with torch.no_grad():\n",
            "        for data, target in data_loader:\n",
            "            data, target = data.to(device), target.to(device)\n",
            "            output = model(data)\n",
            "\n",
            "            # Calculate the number of correct predictions\n",
            "            pred = output.argmax(dim=1, keepdim=True)\n",
            "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
            "\n",
            "# Calculate and print the test accuracy\n",
            "\ndef visualize_predictions(model, data_loader, device):\n",
            "\test_accuracy = 100.0 * correct / len(data_loader.dataset)\nprint(f'Test accuracy: {test_accuracy:.2f}%')\n"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "# Visualize some predictions"
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "import matplotlib.pyplot as plt\n",
            "\n",
            "def visualize_predictions(model, data_loader, device):\n",
            "    model.eval()\n",
            "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
            "\n",
            "    with torch.no_grad():\n",
            "        for data, target in data_loader:\n",
            "            data = data.to(device)\n",
            "            output = model(data)\n",
            "\n",
            "            # Get the predicted class for each image\n",
            "            preds = output.argmax(dim=1)\n",
            "\n",
            "            # Plot the images and their predicted labels\n",
            "            for i in range(10):\n",
            "                ax = axes[i // 5][i % 5]\n",
            "                ax.imshow(data[i].cpu().numpy().squeeze(), cmap='gray')\n",
            "                ax.set_title(f'Predicted: {preds[i].item()}')\n",
            "            break\n",
            "\n"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "# Practical Application: Digit Recognition"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Now that we have a trained model for digit classification, we can use it to recognize handwritten digits in real-world situations. For example, recognizing handwritten digits on forms or documents, or even creating a digit recognition app that allows users to draw digits with their finger on a touchscreen device."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "In this tutorial, we learned about the basic structure of neural networks, including input, hidden, and output layers. We designed and trained a neural network for classifying handwritten digits using the MNIST dataset. Finally, we discussed the practical applications of digit recognition in real-world scenarios."
        ],
        "metadata": {}
    }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
