{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1304c9d7",
   "metadata": {},
   "source": [
    "# PyTorch Tensors Tutorial\n",
    "\n",
    "In this tutorial, we will learn about PyTorch Tensors. Tensors in PyTorch are similar to NumPy's ndarrays, with the addition being that Tensors can also be used on a GPU for accelerating the computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304c9d7",
   "metadata": {},
   "source": [
    "# Install Torch if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9aba3a",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "\n",
    "Tensors can be created in multiple ways. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ecbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directly from data\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "# From a NumPy array\n",
    "import numpy as np\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "# From another tensor:\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
    "\n",
    "# With random or constant values:\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfa7a2",
   "metadata": {},
   "source": [
    "## Tensor Attributes\n",
    "\n",
    "Tensors have attributes like shape, datatype, and the device they are stored on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824510d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82276176",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "There are multiple syntaxes for operations. In the following examples, we will review the addition operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "\n",
    "# Standard numpy-like indexing and slicing:\n",
    "tensor = torch.ones(4, 4)\n",
    "print('First row: ',tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)\n",
    "\n",
    "# Joining tensors\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)\n",
    "\n",
    "# Arithmetic Operations\n",
    "# This computes the matrix multiplication between two tensors\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a1b0e",
   "metadata": {},
   "source": [
    "## More Tensor Operations\n",
    "\n",
    "Let's continue with more operations on Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")\n",
    "\n",
    "# In-place operations Operations that have a _ suffix are in-place.\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e724e",
   "metadata": {},
   "source": [
    "## Bridge with NumPy\n",
    "\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ac56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "# A change in the tensor reflects in the NumPy array.\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f181fb0",
   "metadata": {},
   "source": [
    "## NumPy Array to Tensor\n",
    "\n",
    "Conversely, changes in the NumPy array will reflect in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n",
    "# Changes in the NumPy array reflects in the tensor.\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bdd916",
   "metadata": {},
   "source": [
    "## Gradient tracking\n",
    "\n",
    "PyTorch can automatically compute the gradient or derivative of the tensor which is particularly useful for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849095bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This flag allows to track the computation history on the tensor for gradient computation\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "# An operation of this tensor is:\n",
    "y = x + 2\n",
    "print(y)\n",
    "\n",
    "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
    "# grad_fn: encodes its history\n",
    "print(y.grad_fn)\n",
    "\n",
    "# More operations on y\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba3e396",
   "metadata": {},
   "source": [
    "## Computing Gradients\n",
    "\n",
    "Let's compute the gradients with backpropagation. When we finish our computation we can call .backward() and have all the gradients computed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5cbeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute gradients\n",
    "out.backward()\n",
    "# print gradients d(out)/dx\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ff696",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This tutorial introduced you to PyTorch Tensors and the key operations and properties you can perform with them. With these fundamentals, you are ready to start diving into more advanced topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
