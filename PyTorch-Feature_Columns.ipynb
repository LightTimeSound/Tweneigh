{
   "cells": [
    {
        "cell_type": "markdown",
        "source": [
            "# Feature Columns in PyTorch"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Introduction to Feature Columns"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Feature columns are an important concept in machine learning, as they help in transforming raw data into a format that can be easily understood by machine learning models. In the context of PyTorch, feature columns are not explicitly defined as a separate module or class; instead, they are a part of the data preprocessing step.\n\nIn this tutorial, we will discuss how to create feature columns in PyTorch using a sample dataset. We will also cover the different types of feature columns and how they can be used to improve the performance of deep learning models."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Dataset and Context"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "We will use a simple dataset containing information about houses, such as the number of rooms, area, and price. Our goal is to predict the price of a house based on its features. The dataset is given below:"
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "import torch\n",
            "\n",
            "# Sample dataset\n",
            "# Columns: [Number_of_rooms, Area (sq.m), Price]\n",
            "\n",
            "data = torch.tensor([\n",
            "[2, 50, 150000],\n",
            "[3, 75, 210000],\n",
            "[4, 90, 280000],\n",
            "[2, 40, 120000],\n",
            "[1, 30, 90000],\n",
            "[5, 110, 330000]\n",
            "], dtype=torch.float32)\n",
            "\n",
            "print('Dataset:')\n",
            "print(data)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Types of Feature Columns"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "There are several types of feature columns that can be used to preprocess the data. Some of them are:\n\n1. **Numeric columns:** These columns represent numerical features and can be directly used as input to the model.\n\n2. **Categorical columns:** These columns represent categorical features and need to be converted into a numerical format using techniques like one-hot encoding or embedding.\n\n3. **Bucketized columns:** These columns represent continuous numerical features that can be divided into discrete intervals or buckets.\n\n4. **Crossed columns:** These columns represent combinations of multiple categorical features.\n\nWe will now demonstrate how to create these feature columns in PyTorch."
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Numeric Columns"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Numeric columns can be directly used as input to the model. In our dataset, the number of rooms and area are numeric features. We will normalize these features using min-max normalization."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Normalize numeric features\n",
            "numeric_features = data[:, 0:2]\n",
            "min_values = torch.min(numeric_features, dim=0)[0]\n",
            "max_values = torch.max(numeric_features, dim=0)[0]\n",
            "normalized_numeric_features = (numeric_features - min_values) / (max_values - min_values)\n",
            "\n",
            "print('Normalized Numeric Features:')\n",
            "print(normalized_numeric_features)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Categorical Columns"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "In this example, we do not have any categorical features. However, if we had a categorical feature like 'neighborhood', we could use one-hot encoding or embedding to convert it into a numerical format. Here's an example of how to do one-hot encoding in PyTorch:"
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Example: One-hot encoding\n",
            "# Assume the 'neighborhood' feature has three unique values: A, B, and C\n",
            "\n",
            "# Convert the categorical feature to integer indices\n",
            "# neighborhood_indices = ...\n",
            "\n",
            "# Perform one-hot encoding\n",
            "# one_hot_neighborhood = torch.nn.functional.one_hot(neighborhood_indices)\n"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Bucketized Columns"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "We can create bucketized columns by dividing continuous numerical features into discrete intervals or buckets. For example, we can divide the 'area' feature into three buckets: small (0-50 sq.m), medium (51-100 sq.m), and large (101-150 sq.m)."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Bucketize the 'area' feature\n",
            "area_feature = data[:, 1]\n",
            "bucketized_area = torch.bucketize(area_feature, boundaries=torch.tensor([50, 100]))\n",
            "\n",
            "print('Bucketized Area:')\n",
            "print(bucketized_area)"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Crossed Columns"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Crossed columns represent combinations of multiple categorical features. In this example, we do not have any categorical features to create crossed columns. However, if we had two categorical features like 'neighborhood' and 'property_type', we could create a crossed column as follows:"
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Example: Crossed column\n",
            "# Assume the 'neighborhood' and 'property_type' features are already converted to integer indices\n",
            "\n",
            "# Combine the two categorical features\n",
            "# combined_features = neighborhood_indices * num_property_types + property_type_indices\n"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Training a Model with Feature Columns"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Once we have created the feature columns, we can use them as input to train a deep learning model in PyTorch. For this example, we will use a simple linear regression model to predict the house prices based on the numeric and bucketized features."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "from torch.optim import SGD\n",
            "\n",
            "# Combine numeric and bucketized features\n",
            "input_features = torch.cat((normalized_numeric_features, torch.nn.functional.one_hot(bucketized_area)), dim=1)\n",
            "\n",
            "# Create a linear regression model\n",
            "model = nn.Linear(input_features.shape[1], 1)\n",
            "\n",
            "# Define loss function and optimizer\n",
            "criterion = nn.MSELoss()\n",
            "optimizer = SGD(model.parameters(), lr=0.01)\n",
            "\n",
            "# Train the model\n",
            "for epoch in range(1000):\n",
            "    optimizer.zero_grad()\n",
            "    predictions = model(input_features)\n",
            "    loss = criterion(predictions.squeeze(), data[:, 2])\n",
            "    loss.backward()\n",
            "    optimizer.step()\n",
            "\n",
            "# Save the trained model\n",
            "torch.save(model.state_dict(), 'trained_model.pt')"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Loading and Evaluating the Model"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "We can load the trained model and use it to make predictions on new data. To evaluate the performance of the model, we can calculate metrics such as Mean Squared Error (MSE) or R-squared (R2) score."
        ],
        "metadata": {}
    },
    {
        "cell_type": "code",
        "source": [
            "# Load the trained model\n",
            "loaded_model = nn.Linear(input_features.shape[1], 1)\n",
            "loaded_model.load_state_dict(torch.load('trained_model.pt'))\n",
            "# Make predictions on new data\n",
            "# new_data = ...\n",
            "# Prepare new data's features\n",
            "# ...\n",
            "# Make predictions using the loaded model\n",
            "# predictions = loaded_model(new_features)\n",
            "# Evaluate the model performance\n",
            "# mse = criterion(predictions.squeeze(), new_data[:, 2])\n",
            "# r2_score = 1 - mse / torch.var(new_data[:, 2])\n",
            "# Print evaluation metrics\n",
            "# print('Mean Squared Error:', mse.item())\n",
            "# print('R-squared Score:', r2_score.item())"
        ],
        "metadata": {},
        "outputs": [],
        "execution_count": null
    },
    {
        "cell_type": "markdown",
        "source": [
            "## Practical Applications"
        ],
        "metadata": {}
    },
    {
        "cell_type": "markdown",
        "source": [
            "Feature columns play a crucial role in preparing raw data for machine learning models. They can be used to transform and engineer features in various ways, such as normalizing numeric features, bucketizing continuous features, or creating crossed columns.\n\nBy leveraging feature columns effectively, you can improve the performance of your deep learning models and create more accurate predictions. In practice, this can help you build better recommendation systems, predictive maintenance systems, fraud detection systems, and many other applications."
        ],
        "metadata": {}
    }
],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
